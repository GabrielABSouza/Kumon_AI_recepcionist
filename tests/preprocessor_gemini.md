perfeito â€” vamos focar na integraÃ§Ã£o Preprocessor â†’ Gemini Orchestrator com TDD, incluindo testes de compreensÃ£o de contexto. abaixo estÃ¡ a estrutura de testes proposta, os casos essenciais (com Given/When/Then) e snippets pytest com mocks do Gemini.

Estrutura de pastas (tests)
tests/
  conftest.py
  helpers/
    factories.py                 # builders de mensagens e estados
    gemini_stubs.py              # respostas simuladas do Gemini
  preprocessor/
    test_preprocessor_contract.py # (jÃ¡ existe da fase 1)
  orchestrator/
    test_orchestrator_contract.py
    test_orchestrator_context_understanding.py
    test_orchestrator_thresholds.py
    test_orchestrator_error_handling.py
    test_orchestrator_performance.py
    test_orchestrator_logging_tracing.py

Escopo do que vamos testar

Contrato e Interface

Recebe PreprocessedMessage e retorna ClassificationResult com:

intent (enum: greeting, info_request, qualification, scheduling, fallback)

confidence (0â€“1)

entities (dict leve)

routing_hint (opcional)

Nunca gera texto final (apenas classifica).

CompreensÃ£o de contexto (context understanding)

Usa janela de contexto (histÃ³rico curto) para desambiguar:

ReferÃªncias pronominais (â€œele/isso/isso aÃ­â€)

ContinuaÃ§Ã£o de tÃ³pico (â€œsobre preÃ§osâ€¦ e horÃ¡rios?â€)

MudanÃ§a de intenÃ§Ã£o apÃ³s objeÃ§Ã£o (â€œachei caroâ€ â†’ objection vs info_request)

Idioma/variaÃ§Ã£o (â€œoiâ€, â€œolaâ€, â€œolÃ¡â€, PT-BR vs PT-PT)

CÃ³digo-mesclado (mensagem com nÃºmeros/emoji/link)

â€œfromMeâ€/eco nÃ£o afeta contexto

Thresholds e ambiguidade

Faixas: alto (â‰¥0.8), mÃ©dio (0.5â€“0.79), baixo (<0.5)

Em ambiguidades, retorna intent=fallback + confidence<0.5 + routing_hint=request_clarification.

Robustez operacional

Timeout e retry (orquestrador aplica timeout curto e 1 retry)

Erros do provider â†’ degrade para fallback com confidence=0.0

Entradas vazias ou sanitizadas ao extremo â†’ fallback.

Observabilidade

Logs estruturados: ORCH|start|â€¦, ORCH|complete|intent=â€¦|confidence=â€¦|latency_ms=â€¦

Trace id/turn id propagados do preprocessor.

Performance

SLO: p95 â‰¤ 150ms (usando mock de rede)

Teste garante orÃ§amento de latÃªncia (sem I/O real).

Casos de Teste (resumo Given/When/Then)
A) Contrato bÃ¡sico

Given mensagem prÃ©-processada â€œolÃ¡â€

When orquestrador consulta Gemini

Then retorna intent=greeting, confidenceâ‰¥0.8, entities={} e nÃ£o retorna texto gerado.

B) Contexto: referÃªncia pronominal

Given histÃ³rico: usuÃ¡rio perguntou preÃ§o; mensagem atual: â€œe ele inclui material?â€

When classificar

Then intent=information_request, entities={"topic":"pricing","subtopic":"materials"}.

C) MudanÃ§a de intenÃ§Ã£o apÃ³s objeÃ§Ã£o

Given histÃ³rico sobre matrÃ­cula; mensagem: â€œachei caro, tem desconto?â€

Then intent=objection ou information_request com routing_hint="pricing_discount", confidenceâ‰¥0.7.

D) Ambiguidade controlada

Given mensagem: â€œlegalâ€ (sem contexto)

Then intent=fallback, confidence<0.5, routing_hint="request_clarification".

E) Idioma/variaÃ§Ã£o

Given â€œboa tarde, queria infos do mÃ©todoâ€

Then intent=information_request, entities={"topic":"method"}.

F) Rate-limit/sanitizaÃ§Ã£o jÃ¡ aplicados

Given entrada sanitizada (tags removidas)

Then classifica normalmente (nÃ£o re-sanitiza).

G) Timeout/erro do provider

Given Gemini nÃ£o responde em N ms ou lanÃ§a erro

Then intent=fallback, confidence=0.0, log ORCH|error|timeout.

H) Thresholds

Given mensagem ambÃ­gua (â€œpode ser amanhÃ£?â€ sem contexto)

Then confidence entre 0.5â€“0.79 e routing_hint="ask_time_context".

I) Performance

Given 50 chamadas concorrentes (mock)

Then p95 â‰¤ 150ms, nenhum leak de sessÃ£o.

J) Observabilidade

Given uma classificaÃ§Ã£o bem-sucedida

Then logs contÃªm keys: trace_id, turn_id, intent, confidence, latency_ms.

Snippets (pytest) â€” essenciais
conftest.py (fixture principal)
import pytest
from app.core.models import PreprocessedMessage
from tests.helpers.gemini_stubs import GeminiStub

@pytest.fixture
def gemini_stub():
    return GeminiStub()

@pytest.fixture
def orchestrator(gemini_stub):
    from app.core.gemini_orchestrator import GeminiOrchestrator
    return GeminiOrchestrator(client=gemini_stub, timeout_ms=120, retries=1)

@pytest.fixture
def base_msg():
    return PreprocessedMessage(
        phone="555199999999",
        text="olÃ¡",
        headers={"x-forwarded-for":"1.2.3.4"},
        from_me=False,
        history=[]
    )

helpers/gemini_stubs.py
class GeminiStub:
    def __init__(self):
        self.behavior = "ok"
        self.next_response = {"intent":"greeting","confidence":0.92,"entities":{}}

    async def classify(self, prompt):
        if self.behavior == "timeout":
            raise TimeoutError("mock timeout")
        if self.behavior == "error":
            raise RuntimeError("mock provider error")
        return self.next_response

test_orchestrator_contract.py
import pytest

@pytest.mark.asyncio
async def test_contract_basic(orchestrator, base_msg, gemini_stub):
    gemini_stub.next_response = {"intent":"greeting","confidence":0.9,"entities":{}}
    result = await orchestrator.classify(base_msg)
    assert result.intent == "greeting"
    assert result.confidence >= 0.8
    assert isinstance(result.entities, dict)
    # garante que nÃ£o tem texto final
    assert not getattr(result, "generated_text", None)

test_orchestrator_context_understanding.py
import pytest
from app.core.models import PreprocessedMessage, HistoryTurn

@pytest.mark.asyncio
async def test_context_pronoun_resolution(orchestrator, gemini_stub):
    hist = [
        HistoryTurn(role="user", text="Quais os preÃ§os?"),
        HistoryTurn(role="assistant", text="Temos planos X e Y.")
    ]
    msg = PreprocessedMessage(
        phone="5551", text="e ele inclui material?",
        headers={}, from_me=False, history=hist
    )
    gemini_stub.next_response = {
        "intent":"information_request",
        "confidence":0.86,
        "entities":{"topic":"pricing","subtopic":"materials"}
    }
    result = await orchestrator.classify(msg)
    assert result.intent == "information_request"
    assert result.entities.get("topic") == "pricing"
    assert result.confidence >= 0.8

test_orchestrator_thresholds.py
import pytest

@pytest.mark.asyncio
async def test_ambiguous_returns_fallback(orchestrator, base_msg, gemini_stub):
    base_msg.text = "legal"
    gemini_stub.next_response = {"intent":"fallback","confidence":0.42,"entities":{}, "routing_hint":"request_clarification"}
    result = await orchestrator.classify(base_msg)
    assert result.intent == "fallback"
    assert result.confidence < 0.5
    assert result.routing_hint == "request_clarification"

test_orchestrator_error_handling.py
import pytest

@pytest.mark.asyncio
async def test_timeout_degrades_to_fallback(orchestrator, base_msg, gemini_stub):
    gemini_stub.behavior = "timeout"
    result = await orchestrator.classify(base_msg)
    assert result.intent == "fallback"
    assert result.confidence == 0.0

test_orchestrator_performance.py
import asyncio
import statistics
import pytest

@pytest.mark.asyncio
async def test_p95_latency(orchestrator, base_msg, gemini_stub):
    latencies = []
    async def one_call():
        import time
        t0 = time.perf_counter()
        await orchestrator.classify(base_msg)
        latencies.append((time.perf_counter()-t0)*1000)

    await asyncio.gather(*[one_call() for _ in range(50)])
    p95 = sorted(latencies)[int(0.95*len(latencies))-1]
    assert p95 <= 150

test_orchestrator_logging_tracing.py
import pytest

@pytest.mark.asyncio
async def test_logs_have_trace_keys(orchestrator, base_msg, caplog, gemini_stub):
    caplog.set_level("INFO")
    await orchestrator.classify(base_msg)
    logs = "\n".join([r.message for r in caplog.records])
    assert "ORCH|start" in logs
    assert "ORCH|complete" in logs
    assert "intent=" in logs and "confidence=" in logs

CritÃ©rios de Aceite (Definition of Done)

âœ… Todos os testes acima passando localmente e no CI.

âœ… GeminiOrchestrator.classify() nÃ£o gera texto final.

âœ… Thresholds aplicados corretamente com routing_hint em ambiguidades.

âœ… Logs estruturados presentes nas execuÃ§Ãµes.

âœ… p95 â‰¤ 150ms em ambiente de testes com stubs.

SaÃ­da esperada (resumo executivo ao fim desta fase)

Resumo Executivo â€“ Fase â€œPreprocessor â†’ Gemini Orchestratorâ€

Cobertura: contrato, contexto, thresholds, erros, logs e performance.

AcurÃ¡cia contextual: X/Y cenÃ¡rios crÃ­ticos passaram (pronome, continuidade, objeÃ§Ã£o).

Ambiguidade: corretamente mapeada para fallback com routing_hint.

Robustez: timeouts/erros â†’ degrade seguro; sem texto final gerado.

SLO: p95 = NN ms (â‰¤ 150ms).

PrÃ³ximo passo: integrar saÃ­da do orquestrador ao LangGraph (nÃ³s simples que enviam resposta) mantendo idempotÃªncia.

gemini_orchestrator.md â€” Plano de Testes + SaÃ­das Esperadas
Objetivo

Garantir que o Gemini Orchestrator:

receba um PreprocessedMessage e apenas classifique intenÃ§Ã£o (sem gerar resposta final);

compreenda contexto curto (histÃ³rico imediatamente relevante);

respeite thresholds e sinalize ambiguidade;

degrade com seguranÃ§a em timeout/erros;

forneÃ§a logs estruturados e atenda SLO de latÃªncia com mocks.

Fases (TDD)
Fase 1 â€” Contrato & Interface

Meta: validar a assinatura classify(msg) -> ClassificationResult.
Testes-alvo:

test_contract_basic (intenÃ§Ã£o simples â€œolÃ¡â€)

assegura: intent, confidence, entities, sem generated_text.
CritÃ©rios de aceite:

Todos os testes da fase passam.

Logs mÃ­nimos: ORCH|start, ORCH|complete.

Fase 2 â€” CompreensÃ£o de Contexto

Meta: desambiguar por histÃ³rico curto.
Testes-alvo:

test_context_pronoun_resolution (referÃªncia â€œele/issoâ€)

continuidade de tÃ³pico (preÃ§o â†’ materiais; horÃ¡rios â†’ datas)

mudanÃ§a de intenÃ§Ã£o apÃ³s objeÃ§Ã£o (â€œachei caroâ€¦â€)
CritÃ©rios de aceite:

â‰¥ 90% dos casos de contexto definidos passam.

entities preenchidas quando aplicÃ¡vel (ex.: {"topic":"pricing"}).

Fase 3 â€” Thresholds & Ambiguidade

Meta: mapear incerteza corretamente.
Testes-alvo:

test_ambiguous_returns_fallback (mensagem â€œlegalâ€ sem contexto)

casos 0.5â€“0.79 retornam routing_hint Ãºtil (ex.: request_clarification).
CritÃ©rios de aceite:

Regras de faixa aplicadas corretamente (baixo/mÃ©dio/alto).

routing_hint presente nas ambiguidades.

Fase 4 â€” Robustez Operacional

Meta: comportamento seguro em falhas.
Testes-alvo:

test_timeout_degrades_to_fallback

erro do provider â†’ fallback com confidence=0.0.
CritÃ©rios de aceite:

Sem exceÃ§Ãµes â€œvazandoâ€; logs com ORCH|error|â€¦.

Fase 5 â€” Observabilidade

Meta: rastreabilidade e mediÃ§Ã£o.
Testes-alvo:

test_logs_have_trace_keys (trace_id, turn_id, intent, confidence, latency)
CritÃ©rios de aceite:

Logs estruturados padronizados em todas as execuÃ§Ãµes.

Fase 6 â€” Performance (mock)

Meta: SLO de latÃªncia com stubs.
Testes-alvo:

test_p95_latency (p95 â‰¤ 150ms, 50 chamadas concorrentes)
CritÃ©rios de aceite:

p95 â‰¤ 150ms; zero vazamentos de sessÃ£o/recursos.

SaÃ­da que o agente DEVE retornar ao final de cada fase

Formato curto, objetivo, sem prosa desnecessÃ¡ria.

ğŸ” Resumo Executivo de Falhas â€” Modelo por Fase
FASE: <1..6> - <nome da fase>
STATUS: <APROVADA | REPROVADA>

TESTES FALHOS (nome â†’ motivo curto):
- <arquivo::teste> â†’ <asserÃ§Ã£o/expectativa quebrada>
- <arquivo::teste> â†’ <...>

HIPÃ“TESES DE CAUSA RAIZ:
- <bullet 1>
- <bullet 2>

EVIDÃŠNCIAS (curtas):
- logs: <ORCH|error|... / ORCH|complete|intent=...,confidence=...>
- mÃ©tricas: p95=<ms> (se fase 6)
- diffs relevantes: <arquivo/linha> (se houver)

AÃ‡Ã•ES RECOMENDADAS (prioridade â†‘):
1) <mudanÃ§a especÃ­fica de cÃ³digo ou tratamento>
2) <ajuste de prompt ou parsing>
3) <melhoria de log/telemetria>

BLOQUEIOS/DEPENDÃŠNCIAS:
- <se houver>


ObservaÃ§Ã£o: se STATUS = APROVADA, listar â€œTESTES FALHOSâ€ vazio e manter EVIDÃŠNCIAS mÃ­nimas (p.ex. â€œtodos verdes, p95=XXmsâ€).

SaÃ­da final (fim do ciclo TDD do Orchestrator)
ğŸ§¾ Resumo Executivo â€” Encerramento do Orchestrator
COBERTURA: <% aproximado> (X/Y testes)
ROBUSTEZ: timeouts/erros â†’ fallback OK (evidÃªncias: ORCH|error|timeout)
CONTEXTO: <% acerto cenÃ¡rios contexto> (listar 1 exemplo vÃ¡lido)
THRESHOLDS: <comportamento verificado> (ex.: fallback<0.5; hints 0.5â€“0.79)
OBSERVABILIDADE: logs padronizados (trace_id, turn_id, latency_ms OK)
PERFORMANCE (mock): p95=<ms> (target â‰¤150ms) | p99=<ms> (opcional)

RISKS/DEBTS:
- <itens curtos e acionÃ¡veis>

PRÃ“XIMO PASSO:
- Integrar saÃ­da do Orchestrator ao LangGraph (nÃ³s simples â€œsend & returnâ€).

Diretrizes de implementaÃ§Ã£o (para o agente)

NÃ£o gerar texto final no GeminiOrchestrator; apenas ClassificationResult.

Sem re-sanitizaÃ§Ã£o: confiar no PreprocessedMessage.

Timeout curto + 1 retry; erros â†’ fallback (confidence=0.0).

Logs padronizados: ORCH|start, ORCH|complete, ORCH|error, com trace_id, turn_id, latency_ms.

Sem criaÃ§Ã£o de componentes extras: manter-se ao escopo do arquivo e interfaces definidos pelos testes.

EntregÃ¡veis esperados do agente por fase

CÃ³digo mÃ­nimo para passar os testes daquela fase.

Resumo Executivo de Falhas (modelo acima).

Nenhum novo mÃ³dulo/pacote alÃ©m do estipulado (orchestrator + modelos).

Sem duplicar funcionalidades do preprocessor/delivery.
