"""
üéØ TESTE DE INTEGRA√á√ÉO PONTA A PONTA: Full Conversation Flow

Este teste valida o fluxo conversacional completo desde o master_router
at√© a resposta final, simulando exatamente como o sistema funciona em produ√ß√£o.

DIFEREN√áA CR√çTICA dos testes unit√°rios:
- N√£o chama qualification_node diretamente
- Chama o graph.ainvoke() que invoca master_router ‚Üí qualification_node
- Testa a passagem de estado real entre componentes
- Reproduz bugs de integra√ß√£o que testes unit√°rios n√£o capturam

Este √© o teste que importa. Se passar, a aplica√ß√£o funcionar√° em produ√ß√£o.
"""

from unittest.mock import patch

import pytest

from app.core.langgraph_flow import build_graph


class TestFullConversationFlow:
    """
    üö® TESTE DE INTEGRA√á√ÉO: Simula a arquitetura real da aplica√ß√£o

    Este teste falha intencionalmente (Red Phase) para expor bugs de
    integra√ß√£o que os testes unit√°rios n√£o capturam.
    """

    @pytest.fixture
    def graph(self):
        """Build the actual LangGraph workflow used in production."""
        return build_graph()

    @pytest.mark.asyncio
    async def test_qualification_extraction_bug_fixed(self, graph):
        """
        üéØ TESTE ESPEC√çFICO: Verifica se 'ol√°' n√£o √© mais extra√≠do como parent_name

        Este teste for√ßa o fluxo para qualification_node e verifica se nossa corre√ß√£o
        da extra√ß√£o funciona corretamente.
        """
        print("üéØ TESTANDO FIX DA EXTRA√á√ÉO DE 'ol√°' COMO NOME")

        # Estado que for√ßa roteamento para qualification (simulando continua√ß√£o)
        state_with_greeting_sent = {
            "text": "ol√°",
            "phone": "5511999999999",
            "instance": "kumon_assistant",
            "message_id": "test_extraction_fix",
            "greeting_sent": True,  # For√ßa roteamento para qualification
        }

        result = await graph.ainvoke(state_with_greeting_sent)

        print(f"ü§ñ RESPOSTA: {result.get('response', 'N/A')}")
        print(f"üìä DADOS COLETADOS: {result.get('collected_data', {})}")

        # ASSERTIVA CR√çTICA: 'ol√°' N√ÉO deve ser extra√≠do como parent_name
        collected_data = result.get("collected_data", {})
        assert (
            collected_data.get("parent_name") != "ol√°"
        ), f"BUG AINDA EXISTE: 'ol√°' foi extra√≠do como parent_name: {collected_data}"

        # Deve pedir o nome corretamente
        response = result.get("response", "").lower()
        assert any(
            keyword in response
            for keyword in [
                "qual √© o seu nome",
                "seu nome",
                "como voc√™ se chama",
                "nome",
            ]
        ), f"Deveria pedir o nome, mas respondeu: '{result.get('response', '')}'"

        print("‚úÖ FIX CONFIRMADO: 'ol√°' n√£o √© mais extra√≠do como nome!")
        return True

    @pytest.mark.asyncio
    async def test_full_qualification_flow_from_router(self, graph):
        """
        üéØ TESTE CR√çTICO: Fluxo completo de qualifica√ß√£o via master_router

        Este teste simula exatamente o que acontece em produ√ß√£o:
        1. master_router recebe estado com 'text'
        2. master_router roteia para qualification_node
        3. qualification_node_wrapper converte estado
        4. qualification_node processa e retorna resposta

        SE ESTE TESTE PASSAR, O SISTEMA FUNCIONA EM PRODU√á√ÉO.
        """
        print("üéØ INICIANDO TESTE DE INTEGRA√á√ÉO PONTA A PONTA")

        # ========== TURNO 1: Usu√°rio diz "ol√°" ==========
        print("üìû TURNO 1: Usu√°rio envia 'ol√°'")

        initial_state = {
            "text": "ol√°",
            "phone": "5511999999999",
            "instance": "kumon_assistant",
            "message_id": "test_msg_001",
        }

        # Chama o grafo real (master_router ‚Üí qualification_node)
        state_after_turn1 = await graph.ainvoke(initial_state)

        print(f"ü§ñ RESPOSTA TURNO 1: {state_after_turn1.get('response', 'N/A')}")

        # ASSERTIVA 1: Bot deve pedir o nome
        bot_response_1 = state_after_turn1.get("response", "").lower()
        assert any(
            keyword in bot_response_1
            for keyword in [
                "qual √© o seu nome",
                "seu nome",
                "como voc√™ se chama",
                "nome",
            ]
        ), f"Bot deveria pedir o nome, mas respondeu: '{bot_response_1}'"

        print("‚úÖ TURNO 1 OK: Bot pediu o nome corretamente")

        # ========== TURNO 2: Usu√°rio fornece nome "Gabriel" ==========
        print("üìû TURNO 2: Usu√°rio fornece nome 'Gabriel'")

        # CR√çTICO: Atualizar o estado com a nova mensagem do usu√°rio
        # Este √© o ponto onde bugs de integra√ß√£o acontecem!
        state_after_turn1["text"] = "Gabriel"
        state_after_turn1["message_id"] = "test_msg_002"

        # Chama o grafo novamente com estado atualizado
        state_after_turn2 = await graph.ainvoke(state_after_turn1)

        print(f"ü§ñ RESPOSTA TURNO 2: {state_after_turn2.get('response', 'N/A')}")

        # ASSERTIVA 2: Bot deve perguntar sobre beneficiary_type
        # ESTA ASSERTIVA VAI FALHAR se houver bug de integra√ß√£o
        bot_response_2 = state_after_turn2.get("response", "").lower()
        assert any(
            keyword in bot_response_2
            for keyword in [
                "para voc√™ mesmo ou para outra pessoa",
                "√© para voc√™",
                "para quem √©",
                "benefici√°rio",
            ]
        ), (
            f"Bot deveria perguntar sobre benefici√°rio ap√≥s coletar nome, "
            f"mas respondeu: '{bot_response_2}'"
        )

        print("‚úÖ TURNO 2 OK: Bot perguntou sobre benefici√°rio corretamente")

        # ========== TURNO 3: Usu√°rio responde "para meu filho" ==========
        print("üìû TURNO 3: Usu√°rio responde 'para meu filho'")

        state_after_turn2["text"] = "para meu filho"
        state_after_turn2["message_id"] = "test_msg_003"

        state_after_turn3 = await graph.ainvoke(state_after_turn2)

        print(f"ü§ñ RESPOSTA TURNO 3: {state_after_turn3.get('response', 'N/A')}")

        # ASSERTIVA 3: Bot deve perguntar nome da crian√ßa
        bot_response_3 = state_after_turn3.get("response", "").lower()
        assert any(
            keyword in bot_response_3
            for keyword in [
                "qual √© o nome",
                "nome da crian√ßa",
                "como se chama",
                "nome do seu filho",
            ]
        ), f"Bot deveria perguntar nome da crian√ßa, mas respondeu: '{bot_response_3}'"

        print("‚úÖ TURNO 3 OK: Bot perguntou nome da crian√ßa corretamente")

        # ========== VALIDA√á√ÉO FINAL: Verificar dados coletados ==========
        print("üìä VALIDA√á√ÉO: Verificando dados coletados no estado")

        # O estado final deve ter os dados coletados
        collected_data = state_after_turn3.get("collected_data", {})

        # Verificar se Gabriel foi coletado como parent_name
        assert (
            collected_data.get("parent_name") == "Gabriel"
        ), f"parent_name deveria ser 'Gabriel', mas √©: {collected_data.get('parent_name')}"

        # Verificar se beneficiary_type foi coletado como 'child'
        assert (
            collected_data.get("beneficiary_type") == "child"
        ), f"beneficiary_type deveria ser 'child', mas √©: {collected_data.get('beneficiary_type')}"

        print("‚úÖ DADOS COLETADOS CORRETAMENTE:")
        print(f"   üìù parent_name: {collected_data.get('parent_name')}")
        print(f"   üë∂ beneficiary_type: {collected_data.get('beneficiary_type')}")

        print("üéâ TESTE DE INTEGRA√á√ÉO PASSOU! Sistema funciona em produ√ß√£o!")

    @pytest.mark.asyncio
    async def test_graph_router_state_consistency(self, graph):
        """
        üîç TESTE AUXILIAR: Verifica consist√™ncia de estado entre turnos

        Este teste verifica se o estado √© propagado corretamente entre
        chamadas do grafo, sem perda de dados coletados.
        """
        print("üîç TESTE DE CONSIST√äNCIA DE ESTADO")

        # Estado inicial
        state = {
            "text": "Meu nome √© Carlos",
            "phone": "5511888888888",
            "instance": "kumon_assistant",
            "message_id": "test_consistency_001",
        }

        # Primeira execu√ß√£o
        result1 = await graph.ainvoke(state)

        # Verificar se dados foram coletados
        collected_data_1 = result1.get("collected_data", {})
        print(f"üìä Dados ap√≥s 1¬∞ turno: {collected_data_1}")

        # Segunda execu√ß√£o com estado propagado
        result1["text"] = "√© para meu filho Pedro"
        result1["message_id"] = "test_consistency_002"

        result2 = await graph.ainvoke(result1)

        collected_data_2 = result2.get("collected_data", {})
        print(f"üìä Dados ap√≥s 2¬∞ turno: {collected_data_2}")

        # CR√çTICO: Dados do turno anterior devem ser preservados
        assert collected_data_2.get("parent_name") == collected_data_1.get(
            "parent_name"
        ), "Estado n√£o foi preservado entre turnos!"

        print("‚úÖ CONSIST√äNCIA DE ESTADO OK: Dados preservados entre turnos")

    @pytest.mark.asyncio
    async def test_master_router_to_qualification_integration(self, graph):
        """
        üéØ TESTE ESPEC√çFICO: Integra√ß√£o master_router ‚Üí qualification_node

        Foca especificamente na passagem de estado entre master_router
        e qualification_node via qualification_node_wrapper.
        """
        print("üîó TESTE DE INTEGRA√á√ÉO ROUTER‚ÜíQUALIFICATION")

        # Estado que deve for√ßar roteamento para qualification (usando greeting_sent)
        state = {
            "text": "Meu nome √© Jo√£o",
            "phone": "5511777777777",
            "instance": "kumon_assistant",
            "message_id": "test_integration_001",
            "greeting_sent": True,  # For√ßa roteamento para qualification
        }

        result = await graph.ainvoke(state)

        print(f"üéØ Resultado da integra√ß√£o: {result.get('response', 'N/A')}")

        # O teste deve confirmar que:
        # 1. N√£o houve erro de execu√ß√£o
        # 2. O qualification_node_wrapper funcionou
        # 3. Alguma resposta foi gerada

        # Verificar se houve resposta ou se foi para qualification
        assert (
            result.get("response") or result.get("current_stage") == "qualification"
        ), (
            f"Integra√ß√£o falhou - sem resposta ou est√°gio incorreto. "
            f"Response: {result.get('response')}, Stage: {result.get('current_stage')}"
        )

        # Se Jo√£o foi extra√≠do como nome, a integra√ß√£o funcionou
        collected_data = result.get("collected_data", {})
        if collected_data.get("parent_name") == "Jo√£o":
            print("‚úÖ INTEGRA√á√ÉO OK: Nome extra√≠do corretamente")
        else:
            # Pelo menos deve ter passado pelo qualification_node sem erro
            print(f"‚ÑπÔ∏è  INTEGRA√á√ÉO OK: Estado processado - {collected_data}")

        print("‚úÖ INTEGRA√á√ÉO ROUTER‚ÜíQUALIFICATION OK")

    @pytest.mark.asyncio
    async def test_full_contextual_turn_works_end_to_end(self, graph):
        """
        üéØ TESTE DE INTEGRA√á√ÉO CONTEXTUAL: Nova arquitetura com GeminiClassifier inteligente

        Este teste define a nova arquitetura onde o GeminiClassifier tem mem√≥ria de curto prazo
        atrav√©s do hist√≥rico da conversa e se torna o principal motor de extra√ß√£o de entidades.

        ARQUITETURA TESTADA:
        1. Master Router coleta contexto e chama GeminiClassifier
        2. GeminiClassifier recebe hist√≥rico + mensagem atual e extrai entidades
        3. qualification_node recebe nlu_result com entidades prontas
        4. qualification_node valida/salva entidades e gera pr√≥xima pergunta

        üî• ESTE TESTE VAI FALHAR (Red Phase) - expondo problemas da arquitetura atual
        """
        print("üéØ INICIANDO TESTE DE INTEGRA√á√ÉO CONTEXTUAL (Red Phase)")

        # ========== TURNO 1: Usu√°rio diz "ol√°" ==========
        print("üìû TURNO 1: Usu√°rio envia 'ol√°' - deve receber greeting")

        initial_state = {
            "text": "ol√°",
            "phone": "5511999999999",
            "instance": "kumon_assistant",
            "message_id": "contextual_test_001",
        }

        # Mock do greeting para evitar depend√™ncia da OPENAI_API_KEY
        with patch("app.core.langgraph_flow.get_openai_client") as mock_openai:
            # Mock needs to return a coroutine, not a string
            async def mock_chat(*_args, **_kwargs):  # noqa: U101
                return "Ol√°! Para come√ßarmos, qual √© o seu nome?"

            mock_openai.return_value.chat = mock_chat

            # Chama o grafo real
            state_after_turn1 = await graph.ainvoke(initial_state)

            print(f"ü§ñ RESPOSTA TURNO 1: {state_after_turn1.get('response', 'N/A')}")

            # VALIDA√á√ÉO TURNO 1: Bot deve pedir o nome
            bot_response_1 = state_after_turn1.get("response", "").lower()
            assert any(
                keyword in bot_response_1
                for keyword in [
                    "qual √© o seu nome",
                    "seu nome",
                    "como voc√™ se chama",
                    "nome",
                ]
            ), f"Turno 1: Bot deveria pedir o nome, mas respondeu: '{bot_response_1}'"

            print("‚úÖ TURNO 1 OK: Bot pediu o nome corretamente")

        # ========== TURNO 2: Usu√°rio fornece nome "Gabriel" ==========
        print(
            "üìû TURNO 2: Usu√°rio fornece nome 'Gabriel' - TESTE CR√çTICO DA NOVA ARQUITETURA"
        )

        # Preparar estado do turno 2 com hist√≥rico
        state_after_turn1["text"] = "Gabriel"
        state_after_turn1["message_id"] = "contextual_test_002"

        # üéØ TESTE CR√çTICO: Mock do GeminiClassifier dentro do qualification_node_wrapper
        with patch("app.core.langgraph_flow.classifier.classify") as mock_classify:
            # Mock precisa retornar diferentes respostas dependendo do contexto
            def mock_classify_func(_text, context=None):  # noqa: U101
                if context is None:
                    # Basic routing call
                    return {
                        "primary_intent": "qualification",
                        "secondary_intent": None,
                        "confidence": 0.95,
                        "entities": {},
                    }
                else:
                    # Contextual call within qualification_node_wrapper
                    return {
                        "primary_intent": "qualification",
                        "secondary_intent": None,
                        "confidence": 0.95,
                        "entities": {
                            "parent_name": "Gabriel"  # üéØ CR√çTICO: Entidade extra√≠da pelo Gemini
                        },
                    }

            mock_classify.side_effect = mock_classify_func

            # Executar turno 2
            state_after_turn2 = await graph.ainvoke(state_after_turn1)

            print(f"ü§ñ RESPOSTA TURNO 2: {state_after_turn2.get('response', 'N/A')}")
            print(
                f"üß™ DEBUG - nlu_entities in state: "
                f"{state_after_turn2.get('nlu_entities', 'NOT_FOUND')}"
            )
            print(
                f"üß™ DEBUG - collected_data: {state_after_turn2.get('collected_data', 'NOT_FOUND')}"
            )

            # ========== VALIDA√á√ÉO CR√çTICA DA NOVA ARQUITETURA ==========

            # ASSERTIVA 1: GeminiClassifier deve ter sido chamado com contexto
            mock_classify.assert_called()
            call_args = mock_classify.call_args

            # Verificar se foi chamado com par√¢metros contextuais
            assert call_args is not None, "GeminiClassifier n√£o foi chamado!"

            # O primeiro argumento deve ser a mensagem do usu√°rio
            user_message = call_args[0][0]
            assert (
                user_message == "Gabriel"
            ), f"Mensagem incorreta: esperava 'Gabriel', recebeu '{user_message}'"

            # O contexto deve conter o hist√≥rico da conversa
            context = call_args.kwargs.get("context", {})
            assert (
                context is not None
            ), "Contexto n√£o foi passado para GeminiClassifier!"

            # Verificar se o contexto tem hist√≥rico (state ou history)
            has_history = ("history" in context and context["history"]) or (
                "state" in context and context["state"]
            )
            assert has_history, f"Contexto sem hist√≥rico: {context}"

            print(
                "‚úÖ ASSERTIVA 1 PASSOU: GeminiClassifier recebeu contexto com hist√≥rico"
            )

            # ASSERTIVA 2: qualification_node deve ter recebido entidades do nlu_result
            # Verificamos isso atrav√©s do estado final - se parent_name foi salvo
            collected_data = state_after_turn2.get("collected_data", {})
            assert collected_data.get("parent_name") == "Gabriel", (
                f"qualification_node n√£o processou entidades do NLU corretamente. "
                f"Esperava parent_name='Gabriel', recebeu: {collected_data}"
            )

            print("‚úÖ ASSERTIVA 2 PASSOU: qualification_node processou entidades do NLU")

            # ASSERTIVA 3: Bot deve gerar pr√≥xima pergunta da sequ√™ncia
            bot_response_2 = state_after_turn2.get("response", "").lower()
            assert any(
                keyword in bot_response_2
                for keyword in [
                    "para voc√™ mesmo ou para outra pessoa",
                    "√© para voc√™",
                    "benefici√°rio",
                ]
            ), (
                f"Bot deveria perguntar sobre benefici√°rio ap√≥s coletar nome, "
                f"mas respondeu: '{bot_response_2}'"
            )

            print("‚úÖ ASSERTIVA 3 PASSOU: Bot gerou pr√≥xima pergunta da sequ√™ncia")

        print("üéâ TESTE DE INTEGRA√á√ÉO CONTEXTUAL PASSOU!")
        print("   üìã Nova arquitetura funcionando:")
        print("   ‚îú‚îÄ GeminiClassifier recebe contexto hist√≥rico ‚úÖ")
        print("   ‚îú‚îÄ GeminiClassifier extrai entidades inteligentemente ‚úÖ")
        print("   ‚îú‚îÄ qualification_node processa entidades do NLU ‚úÖ")
        print("   ‚îî‚îÄ Fluxo conversacional mant√©m continuidade ‚úÖ")

        return True
